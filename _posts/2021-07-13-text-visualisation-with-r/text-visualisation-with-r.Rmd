---
title: "Text visualisation with R"
description: |
  Yesterday, we learnt how to visualise text (unstructured) data.
author:
  - name: Nurulasyiqah Md. Taha
    url: https://www.linkedin.com/in/nurulasyiqah-md-taha/
date: 07-12-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina=3,
                      echo = TRUE, 
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

### Installing and launching R packages

```{r}
packages = c('tidytext', 'tidyverse', 'dplyr', 'ggraph',
             'widyr', 'wordcloud', 'ggwordcloud', 'DT',
             'textplot', 'lubridate', 'hms', 'tidygraph',
             'igraph')
              
for(p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

### Data preparation

We will work with multiple folders containing multiple text files (documents) and learn how to extract and manipulate text data. 

One raw data have been uploaded, raw data should be deleted.

### Import multiple text files from multiple folders

**Step 1**: Create a folder list

```{r eval=FALSE}
news20 <- "data/20news/"
```

**Step 2**: Define a function to read all files from a folder into a data frame

```{r eval=FALSE}
read_folder <- function(infolder) { #writing a function
  tibble(file = dir(infolder,
                    full.names = TRUE)) %>%
    mutate(text = map(file,
                      read_lines)) %>%
    transmute(id = basename(file),
              text) %>%
    unnest(text)
}
```

Note that we don't use if-loop function to look through the files, but "infolder" function. It is similar to writing a R code - nothing will happen till we run Step 3.

**Step 3**: Reading all messages from the 20news folder

```{r eval=FALSE}
raw_text <- tibble(folder = dir(news20, full.names = TRUE)) %>%
  mutate(folder_out = map(folder, read_folder)) %>%
  unnest(cols = c(folder_out)) %>%
  transmute(newsgroup = basename(folder), id, text)
write_rds(raw_text,"data/rds/news20.rds") #output a consolidated data set of raw text in .rds format
```

Note that no. of observations is 7,601.

```{r}
raw_text <- read_rds("data/rds/news20.rds")

glimpse(raw_text)
```

We should now delete all the raw data folders.

### Initial EDA

To check that all raw text have been written into rds:

```{r}
raw_text %>%
  group_by(newsgroup) %>%
  summarise(messages = n_distinct(id)) %>% #count the unique article ID
  ggplot(aes(messages, newsgroup)) +
#x-axis is no of articles, y-axis is the different news outlets
  geom_col(fill = "lightblue") +
  labs(y = NULL)
```


### Cleaning text data

**Step 1**: To remove header and automatic email signatures

```{r}
cleaned_text <- raw_text %>%
  group_by(newsgroup, id) %>%
  filter(cumsum(text == "") > 0,
         cumsum(str_detect(text, "^--")) == 0) %>%
  #to detect string based on your defined pattern
  ungroup()
```

In RStudio "Environment" tab, click on cleaned_text to skim through what needs to be removed next.

**Step 2**: Remove lines with nested text representing quotes from other users.

```{r}
cleaned_text <- cleaned_text %>%
  filter(str_detect(text, "^[^>]+[A-Za-z\\d]")
         | text == "",
         !str_detect(text, "writes(:|\\.\\.\\.)$"),
         !str_detect(text, "^In article <")
  )
```

Note that no. of observations reduced to 4,449.

```{r}
glimpse(cleaned_text)
```

You need to clean the text further because if you glimpse at cleaned_text, text is still dirty.

Refer to [stringr regular expressions](https://stringr.tidyverse.org/articles/regular-expressions.html) for ideas on patterns to define strings to remove.

### Text data processing

Use [unnest_tokens()](https://www.rdocumentation.org/packages/tidytext/versions/0.3.1/topics/unnest_tokens) to split dataset into tokens and [stop_words()](https://rdrr.io/cran/tidytext/man/stop_words.html) to remove stop-words.
